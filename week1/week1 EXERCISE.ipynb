{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up environment\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why. Use markdowns.\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Let's break down the provided code step by step.\n",
      "\n",
      "```python\n",
      "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "\n",
      "1. **Context of `yield from`:**\n",
      "   - The expression begins with `yield from`. This is used in a generator function to yield all values from an iterable. It allows you to \"yield\" multiple values from another generator or iterable without having to loop through it manually.\n",
      "\n",
      "2. **Set Comprehension:**\n",
      "   - Inside the `yield from` expression, we have a **set comprehension**:\n",
      "     ```python\n",
      "     {book.get(\"author\") for book in books if book.get(\"author\")}\n",
      "     ```\n",
      "   - A set comprehension is a concise way to create a set by iterating over an iterable (in this case, `books`) and applying conditions.\n",
      "\n",
      "3. **Iterating through `books`:**\n",
      "   - `for book in books`: This part of the comprehension iterates over each element (which we assume are dictionaries representing books) in the `books` collection (e.g., a list of dictionaries).\n",
      "\n",
      "4. **Getting the author:**\n",
      "   - `book.get(\"author\")`: This method tries to fetch the value associated with the key `\"author\"` from each `book`. If the key doesn't exist, it returns `None` (and does not raise an error).\n",
      "\n",
      "5. **Filtering authors:**\n",
      "   - `if book.get(\"author\")`: This condition checks if the author value is not `None` or evaluates to `False`. If an author exists for a book, it proceeds to add this author to the set.\n",
      "\n",
      "6. **Creating a Set of Authors:**\n",
      "   - The result of the set comprehension will be a set containing unique authors from the given books, effectively filtering out any duplicates and ensuring that only authors who are not `None` are included.\n",
      "\n",
      "### Summary:\n",
      "\n",
      "- **Purpose:** The line of code collects and yields unique authors from a list of book dictionaries, ignoring any books that do not have an associated author.\n",
      "- **Why Use It:** This approach ensures that:\n",
      "  - You efficiently aggregate authors into a set (which inherently eliminates duplicates).\n",
      "  - You can easily yield each unique author, allowing for further processing in whatever generator function this line is part of.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "openai = OpenAI()\n",
    "\n",
    "for chunk in openai.chat.completions.create(\n",
    "    model=MODEL_GPT,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that explains code.\"},\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ],\n",
    "    stream=True\n",
    "):\n",
    "    if chunk.choices[0].delta.content:\n",
    "        # Buffer to accumulate markdown output and print only on newlines\n",
    "        if 'markdown_buffer' not in globals():\n",
    "            markdown_buffer = \"\"\n",
    "        markdown_buffer += chunk.choices[0].delta.content\n",
    "        while \"\\n\" in markdown_buffer:\n",
    "            line, markdown_buffer = markdown_buffer.split(\"\\n\", 1)\n",
    "            print(line)\n",
    "    # Print any remaining buffer at the end (outside the loop, after streaming)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m response.iter_lines():\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m line:\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m         data = \u001b[43mjson\u001b[49m.loads(line.decode(\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m     19\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[32m     20\u001b[39m             \u001b[38;5;28mprint\u001b[39m(data[\u001b[33m'\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m'\u001b[39m], end=\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m, flush=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "\n",
    "import requests\n",
    "\n",
    "# Make sure Ollama is running with: ollama run llama3.2\n",
    "response = requests.post('http://localhost:11434/api/generate', json={\n",
    "    'model': 'llama3.2',\n",
    "    'prompt': f\"\"\"You are a helpful assistant that explains code.\n",
    "\n",
    "User question: {question}\n",
    "\n",
    "Please provide a clear explanation:\"\"\",\n",
    "    'stream': True\n",
    "})\n",
    "\n",
    "for line in response.iter_lines():\n",
    "    if line:\n",
    "        data = json.loads(line.decode('utf-8'))\n",
    "        if 'response' in data:\n",
    "            print(data['response'], end='', flush=True)\n",
    "        if data.get('done', False):\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a83a6b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
